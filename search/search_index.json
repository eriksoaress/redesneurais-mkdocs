{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Entregas Redes Neurais","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#erik-soares","title":"Erik Soares","text":""},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Data - https://eriksoaress.github.io/redesneurais-mkdocs/data/main/</li> <li> Perceptron</li> <li> MLP</li> </ul>"},{"location":"index_template/","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"index_template/#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> <li>Maria Oliveira</li> <li>Grupo K<ul> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> </ul> </li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"index_template/#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"index_template/#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"index_template/#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"index_template/#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"index_template/#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"data/main/","title":"Redes Neurais","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"data/main/#erik-soares","title":"Erik Soares","text":""},{"location":"data/main/#exercicio-1","title":"Exerc\u00edcio 1","text":""},{"location":"data/main/#explorando-a-separabilidade-de-classes-em-2d","title":"Explorando a Separabilidade de Classes em 2D","text":""},{"location":"data/main/#instrucoes","title":"Instru\u00e7\u00f5es","text":"<ol> <li> <p>Gerar os Dados: Crie um conjunto de dados sint\u00e9tico com um total de 400 amostras, divididas igualmente entre 4 classes (100 amostras cada). Utilize uma distribui\u00e7\u00e3o Gaussiana para gerar os pontos para cada classe com base nos seguintes par\u00e2metros:</p> <ul> <li>Classe 0: M\u00e9dia = [2, 3], Desvio Padr\u00e3o = [0.8, 2.5]</li> <li>Classe 1: M\u00e9dia = [5, 6], Desvio Padr\u00e3o = [1.2, 1.9]</li> <li>Classe 2: M\u00e9dia = [8, 1], Desvio Padr\u00e3o = [0.9, 0.9]</li> <li>Classe 3: M\u00e9dia = [15, 4], Desvio Padr\u00e3o = [0.5, 2.0]</li> </ul> </li> <li> <p>Plotar os Dados: Crie um gr\u00e1fico de dispers\u00e3o 2D mostrando todos os pontos de dados. Utilize uma cor diferente para cada classe para torn\u00e1-las distingu\u00edveis.</p> </li> <li> <p>Analisar e Desenhar Limites: </p> </li> <li>Examine o gr\u00e1fico de dispers\u00e3o com aten\u00e7\u00e3o. Descreva a distribui\u00e7\u00e3o e a sobreposi\u00e7\u00e3o das quatro classes.</li> <li>Com base na sua inspe\u00e7\u00e3o visual, um limite simples e linear poderia separar todas as classes?</li> <li>Em seu gr\u00e1fico, esboce os limites de decis\u00e3o que voc\u00ea acha que uma rede neural treinada poderia aprender para separar essas classes.</li> </ol>"},{"location":"data/main/#solucao","title":"Solu\u00e7\u00e3o","text":""},{"location":"data/main/#geracao-e-plotagem-dos-dados","title":"Gera\u00e7\u00e3o e Plotagem dos Dados","text":"<p>O c\u00f3digo abaixo gera os dados sint\u00e9ticos conforme as especifica\u00e7\u00f5es e os plota em um gr\u00e1fico de dispers\u00e3o 2D.</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nparams = {\n    'classe_0': {'media': [2, 3], 'desvio_padrao': [0.8, 2.5], 'n_amostras': 100},\n    'classe_1': {'media': [5, 6], 'desvio_padrao': [1.2, 1.9], 'n_amostras': 100},\n    'classe_2': {'media': [8, 1], 'desvio_padrao': [0.9, 0.9], 'n_amostras': 100},\n    'classe_3': {'media': [15, 4], 'desvio_padrao': [0.5, 2.0], 'n_amostras': 100}\n}\n\nX = []\ny = []\n\nfor i, (classe, p) in enumerate(params.items()):\n    dados_classe = np.random.normal(\n        loc=p['media'],\n        scale=p['desvio_padrao'],\n        size=(p['n_amostras'], 2),\n    )\n\n    X.append(dados_classe)\n    y.append(np.full(p['n_amostras'], fill_value=i))\n\nX = np.concatenate(X)\ny = np.concatenate(y)\n\nplt.figure(figsize=(12, 8))\n\ncores = ['blue', 'orange', 'green', 'red']\nlabels_classes = ['Classe 0', 'Classe 1', 'Classe 2', 'Classe 3']\n\nfor i in range(4):\n    plt.scatter(\n        X[y == i, 0],\n        X[y == i, 1],\n        c=cores[i],\n        label=labels_classes[i],\n        edgecolors='k'\n    )\n\n\nplt.title('Distribui\u00e7\u00e3o das 4 Classes de Dados Sint\u00e9ticos', fontsize=16)\nplt.xlabel('Caracter\u00edstica 1 (X)', fontsize=12)\nplt.ylabel('Caracter\u00edstica 2 (Y)', fontsize=12)\nplt.legend(fontsize=10)\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.axhline(0, color='black', linewidth=0.5)\nplt.axvline(0, color='black', linewidth=0.5)\nplt.show()\n</code></pre> <p></p>"},{"location":"data/main/#analise-e-limites-de-decisao","title":"An\u00e1lise e Limites de Decis\u00e3o","text":"<p>Ap\u00f3s a execu\u00e7\u00e3o do c\u00f3digo acima, ser\u00e1 gerado um gr\u00e1fico de dispers\u00e3o. A an\u00e1lise visual do gr\u00e1fico revela:</p> <ul> <li>Classe 0: A classe 0 \u00e9 a classe que apresenta os dados mais dispersos, principalmente em rela\u00e7\u00e3o a caracter\u00edstica 2 (Y), alguns dados se aproximam e se misturam com dados da classe 1.</li> <li>Classe 1: A classe 1 est\u00e1 localizada acima e a direita da classe 1, mas n\u00e3o t\u00e3o distante, o que permite uma mistura consider\u00e1vel de seus dados, al\u00e9m disso, poucos dados ainda conseguem se misturar com a classe 2. Essa classe tamb\u00e9m apresenta uma certa dispers\u00e3o, em rela\u00e7\u00e3o ao componente 1 e 2, mas ainda menor que a classe 1.</li> <li>Classe 2: A classe dois est\u00e1 localizada a direita da classe 0 e 1, e um pouco para baixo, ela est\u00e1 mais afastada e por isso tem uma mistura m\u00ednima com as outras classes. \u00c9 uma classe com uma dispers\u00e3o bem baixa em rela\u00e7\u00e3o a ambos os componentes.</li> <li>Classe 3: A classe 3 \u00e9 a classe mais isolada, nenhum de seus dados se misturam com outras classes, est\u00e1 totalmente \u00e0 direita. Sua dispers\u00e3o \u00e9 predominantemente em rela\u00e7\u00e3o a caracter\u00edstica 2 (Y).</li> </ul> <p>As classes 0, 1 e 2 parecem ser razoavelmente separ\u00e1veis linearmente, embora possa haver alguma sobreposi\u00e7\u00e3o entre elas. A Classe 3 est\u00e1 bem distante das outras, indicando uma alta separabilidade. Portanto, um limite simples e linear n\u00e3o \u00e9 capaz de separar adequadamente todas as classes, pois h\u00e1 classes que se misturam, e at\u00e9 mesmo pontos de classes diferentes que est\u00e3o praticamente um sob o outro.</p>"},{"location":"data/main/#simulacao-dos-limites-de-decisao","title":"Simula\u00e7\u00e3o dos limites de decis\u00e3o","text":"<p>O c\u00f3digo abaixo esbo\u00e7a os limites de decis\u00e3o lineares que tenta separar as classes: <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nparams = {\n    'classe_0': {'media': [2, 3], 'desvio_padrao': [0.8, 2.5], 'n_amostras': 100},\n    'classe_1': {'media': [5, 6], 'desvio_padrao': [1.2, 1.9], 'n_amostras': 100},\n    'classe_2': {'media': [8, 1], 'desvio_padrao': [0.9, 0.9], 'n_amostras': 100},\n    'classe_3': {'media': [15, 4], 'desvio_padrao': [0.5, 2.0], 'n_amostras': 100}\n}\n\nX = []\ny = []\n\nfor i, (classe, p) in enumerate(params.items()):\n    dados_classe = np.random.normal(\n        loc=p['media'],\n        scale=p['desvio_padrao'],\n        size=(p['n_amostras'], 2),\n    )\n\n    X.append(dados_classe)\n    y.append(np.full(p['n_amostras'], fill_value=i))\n\nX = np.concatenate(X)\ny = np.concatenate(y)\n\nx_line1 = np.array([0, 12])\ny_line1 = -2.9 * x_line1 + 16\nplt.plot(x_line1, y_line1, '-', color='k', lw=2)\n\n\nx_line2 = np.array([2, 12])\ny_line2 = 1.3 * x_line2 - 6\nplt.plot(x_line2, y_line2, '-', color='k', lw=2)\n\nplt.axvline(x=12, linestyle='-', color='k', lw=2)\n\nfor i in range(4):\n    plt.scatter(\n        X[y == i, 0], X[y == i, 1], \n        color=cores[i], \n        edgecolors='k', \n        label=labels_classes[i],\n    )\nplt.title('Distribui\u00e7\u00e3o com Limites de Decis\u00e3o Lineares (Fun\u00e7\u00f5es Afins)', fontsize=16)\nplt.xlabel('Caracter\u00edstica 1 (X)', fontsize=12)\nplt.ylabel('Caracter\u00edstica 2 (Y)', fontsize=12)\nplt.legend(fontsize=11)\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.axhline(0, color='black', linewidth=0.5)\nplt.axvline(0, color='black', linewidth=0.5)\n\nplt.xlim(-1, 17)\nplt.ylim(-3, 14)\n\nplt.show()\n</code></pre> </p>"},{"location":"data/main/#exercicio-2","title":"Exerc\u00edcio 2","text":""},{"location":"data/main/#nao-linearidade-em-dimensoes-superiores","title":"N\u00e3o Linearidade em Dimens\u00f5es Superiores","text":""},{"location":"data/main/#instrucoes_1","title":"Instru\u00e7\u00f5es","text":"<p>Redes neurais simples (como um Perceptron) s\u00f3 podem aprender limites lineares. Redes profundas se destacam quando os dados n\u00e3o s\u00e3o linearmente separ\u00e1veis. Este exerc\u00edcio desafia voc\u00ea a criar e visualizar um conjunto de dados n\u00e3o linearmente separ\u00e1vel.</p> <ol> <li> <p>Gerar os Dados: Crie um conjunto de dados com 500 amostras para a Classe A e 500 amostras para a Classe B. Utilize uma distribui\u00e7\u00e3o normal multivariada com os seguintes par\u00e2metros:</p> <ul> <li> <p>Classe A:</p> <ul> <li>Vetor m\u00e9dio:      <pre><code>\u03bc_A = [0, 0, 0, 0, 0]\n</code></pre></li> <li>Matriz de covari\u00e2ncia:     <pre><code>\u03a3_A = [[1.0, 0.8, 0.1, 0.0, 0.0],\n       [0.8, 1.0, 0.3, 0.0, 0.0],\n       [0.1, 0.3, 1.0, 0.5, 0.0],\n       [0.0, 0.0, 0.5, 1.0, 0.2],\n       [0.0, 0.0, 0.0, 0.2, 1.0]]\n</code></pre></li> </ul> </li> <li> <p>Classe B:</p> <ul> <li>Vetor m\u00e9dio:      <pre><code>\u03bc_B = [1.5, 1.5, 1.5, 1.5, 1.5]\n</code></pre></li> <li>Matriz de covari\u00e2ncia:     <pre><code>\u03a3_B = [[1.5, -0.7, 0.2, 0.0, 0.0],\n       [-0.7, 1.5, 0.4, 0.0, 0.0],\n       [0.2, 0.4, 1.5, 0.6, 0.0],\n       [0.0, 0.0, 0.6, 1.5, 0.3],\n       [0.0, 0.0, 0.0, 0.3, 1.5]]\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Redu\u00e7\u00e3o de Dimensionalidade (PCA): </p> </li> <li> <p>Como os dados est\u00e3o em 5 dimens\u00f5es, utilize a An\u00e1lise de Componentes Principais (PCA) para reduzir a dimensionalidade para 2 componentes principais. Isso permitir\u00e1 a visualiza\u00e7\u00e3o.</p> </li> <li> <p>Crie um gr\u00e1fico de dispers\u00e3o 2D dos dados transformados pela PCA. Utilize uma cor diferente para cada classe.</p> </li> <li> <p>Analisar a Separabilidade: Com base no gr\u00e1fico de dispers\u00e3o, discuta se as classes s\u00e3o linearmente separ\u00e1veis em 2D. Explique por que a n\u00e3o linearidade \u00e9 importante para redes neurais profundas neste contexto.</p> </li> </ol>"},{"location":"data/main/#solucao_1","title":"Solu\u00e7\u00e3o","text":""},{"location":"data/main/#geracao-de-dados-e-reducao-de-dimensionalidade","title":"Gera\u00e7\u00e3o de Dados e Redu\u00e7\u00e3o de Dimensionalidade","text":"<p>O c\u00f3digo abaixo gera os dados para as Classes A e B, e ent\u00e3o aplica PCA para reduzir a dimensionalidade para 2D.</p> <p><pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\nnp.random.seed(42)\n\njn_amostras_A= 500\nn_amostras_B = 500\n\nmedia_A = np.array([0, 0, 0, 0, 0])\nmedia_B = np.array([1.5, 1.5, 1.5, 1.5, 1.5])\n\ncovariancia_A = np.array([\n    [1.0, 0.8, 0.1, 0.0, 0.0],\n    [0.8, 1.0, 0.3, 0.0, 0.0],\n    [0.1, 0.3, 1.0, 0.5, 0.0],\n    [0.0, 0.0, 0.5, 1.0, 0.2],\n    [0.0, 0.0, 0.0, 0.2, 1.0]\n])\n\ncovariancia_B = np.array([\n    [1.5, -0.7, 0.2, 0.0, 0.0],\n    [-0.7, 1.5, 0.4, 0.0, 0.0],\n    [0.2, 0.4, 1.5, 0.6, 0.0],\n    [0.0, 0.0, 0.6, 1.5, 0.3],\n    [0.0, 0.0, 0.0, 0.3, 1.5]\n])\n\nX = np.vstack((dados_A, dados_B))\ny = np.hstack((np.zeros(dados_A.shape[0]), np.ones(dados_B.shape[0])))\n\npca = PCA(n_components=2)\n\ndados_2D = pca.fit_transform(X)\n\n\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.figure(figsize=(10, 8))\n\nplt.scatter(\n    dados_2D[y == 0, 0],\n    dados_2D[y == 0, 1],  \n    c='blue',\n    label='Classe A',\n    alpha=0.7\n)\n\nplt.scatter(\n    dados_2D[y == 1, 0],\n    dados_2D[y == 1, 1],\n    c='red',\n    label='Classe B',\n    alpha=0.7\n)\n\nplt.title('Visualiza\u00e7\u00e3o 2D dos Dados com An\u00e1lise de Componentes Principais (PCA)', fontsize=15)\nplt.xlabel('Primeiro Componente Principal (PC1)', fontsize=12)\nplt.ylabel('Segundo Componente Principal (PC2)', fontsize=12)\nplt.legend(fontsize=12)\nplt.show()\n</code></pre> </p>"},{"location":"data/main/#analise-da-separabilidade","title":"An\u00e1lise da Separabilidade","text":"<p>Ao observar o gr\u00e1fico gerado, \u00e9 evidente que as duas classes (A e B) se sobrep\u00f5em significativamente no espa\u00e7o 2D ap\u00f3s a redu\u00e7\u00e3o de dimensionalidade via PCA. Isso indica que os dados n\u00e3o s\u00e3o linearmente separ\u00e1veis neste espa\u00e7o. Uma \u00fanica linha reta n\u00e3o seria capaz de dividir as duas classes de forma eficaz.</p> <p>Import\u00e2ncia da N\u00e3o Linearidade para Redes Neurais Profundas:</p> <ul> <li> <p>Perceptrons Simples: Um Perceptron simples \u00e9 um classificador linear. Ele s\u00f3 pode aprender limites de decis\u00e3o que s\u00e3o linhas (em 2D), planos (em 3D) ou hiperplanos (em dimens\u00f5es superiores). Se os dados n\u00e3o s\u00e3o linearmente separ\u00e1veis, um Perceptron simples n\u00e3o conseguir\u00e1 classific\u00e1-los corretamente.</p> </li> <li> <p>Redes Neurais Profundas: Redes neurais profundas, com suas m\u00faltiplas camadas ocultas e fun\u00e7\u00f5es de ativa\u00e7\u00e3o n\u00e3o lineares, s\u00e3o capazes de aprender e modelar rela\u00e7\u00f5es complexas e n\u00e3o lineares nos dados. Cada camada oculta pode transformar os dados em uma nova representa\u00e7\u00e3o, onde as classes podem se tornar linearmente separ\u00e1veis. As fun\u00e7\u00f5es de ativa\u00e7\u00e3o n\u00e3o lineares (como ReLU, sigmoid, tanh) s\u00e3o cruciais para essa capacidade, pois introduzem a n\u00e3o linearidade necess\u00e1ria para aprender limites de decis\u00e3o complexos e curvos.</p> </li> </ul> <p>Neste exerc\u00edcio, a sobreposi\u00e7\u00e3o das classes no espa\u00e7o 2D demonstra a necessidade de um modelo mais complexo do que um classificador linear. Redes neurais profundas, com sua arquitetura multicamadas e n\u00e3o linearidades, s\u00e3o ideais para lidar com esse tipo de problema, permitindo a identifica\u00e7\u00e3o de padr\u00f5es e a separa\u00e7\u00e3o de classes que n\u00e3o s\u00e3o trivialmente distingu\u00edveis por uma fronteira linear.</p>"},{"location":"data/main/#exercicio-3","title":"Exerc\u00edcio 3","text":""},{"location":"data/main/#preparando-dados-do-mundo-real-para-uma-rede-neural","title":"Preparando Dados do Mundo Real para uma Rede Neural","text":""},{"location":"data/main/#instrucoes_2","title":"Instru\u00e7\u00f5es","text":"<p>Este exerc\u00edcio utiliza um conjunto de dados real do Kaggle. Sua tarefa \u00e9 realizar o pr\u00e9-processamento necess\u00e1rio para torn\u00e1-lo adequado para uma rede neural que utiliza a tanhfun\u00e7\u00e3o de ativa\u00e7\u00e3o tangente hiperb\u00f3lica ( ) em suas camadas ocultas.</p> <ol> <li>Obtenha os Dados: baixe o conjunto de dados da nave espacial Titanic do Kaggle.</li> <li>Descreva os dados: </li> <li>Descreva brevemente o objetivo do conjunto de dados (ou seja, o que a Transportedcoluna representa?).</li> <li>Liste as caracter\u00edsticas e identifique quais s\u00e3o num\u00e9ricas (por exemplo, Age, RoomService) e quais s\u00e3o categ\u00f3ricas (por exemplo, HomePlanet, Destination).</li> <li>Investigue o conjunto de dados em busca de valores ausentes . Quais colunas os cont\u00eam e quantos?</li> <li>Pr\u00e9-processar os Dados: Seu objetivo \u00e9 limpar e transformar os dados para que possam ser alimentados em uma rede neural. A tanhfun\u00e7\u00e3o de ativa\u00e7\u00e3o produz sa\u00eddas no intervalo [-1, 1], portanto, seus dados de entrada devem ser dimensionados adequadamente para um treinamento est\u00e1vel.<ul> <li>Tratamento de valores ausentes (ex: imputa\u00e7\u00e3o, remo\u00e7\u00e3o).</li> <li>Codifica\u00e7\u00e3o de features categ\u00f3ricas (ex: one-hot encoding, label encoding).</li> <li>Escalonamento de features (ex: MinMaxScaler, StandardScaler).</li> </ul> </li> <li>Visualize os resultados: Crie histogramas para um ou dois recursos num\u00e9ricos (como FoodCourtou Age) antes e depois do dimensionamento para mostrar o efeito da sua transforma\u00e7\u00e3o.</li> </ol>"},{"location":"data/main/#solucao_2","title":"Solu\u00e7\u00e3o","text":""},{"location":"data/main/#carregamento-exploracao-e-tratamento-dos-dados","title":"Carregamento, explora\u00e7\u00e3o e tratamento dos dados","text":"<p>O c\u00f3digo abaixo \u00e9 respons\u00e1vel por carregar, explorar os dados, e tratar tudo o que for necess\u00e1rio para a utiliza\u00e7\u00e3o de um modelo de rede neural.</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\n\nnp.random.seed(42)\n\n# Carregar o dataset\ndf = pd.read_csv(\"./spaceship-titanic/train.csv\")\n\ncontagem_nulos = df.isnull().sum()\nprint(f'Nulos: {contagem_nulos}')\nprint(df.describe())\n\n# Tratamento de valores nulos:\n\ndf['HomePlanet'] = df['HomePlanet'].fillna('Earth') # Foi preenchido com Earth pois \u00e9 o valor predominante (54%)\n\ndf['CryoSleep'] = df['CryoSleep'].fillna(False) # Foi preenchido com False pois \u00e9 o valor predominante (64%)\n\ndf = df.dropna(subset=['Cabin']) # Remove os nulos de cabin, pois n\u00e3o h\u00e1 predomin\u00e2ncia de um valor que possa ser embutido e que n\u00e3o prejudique a an\u00e1lise, como m\u00e9dia, mediana, etc.\n# Al\u00e9m disso, 199 n\u00e3o \u00e9 uma quantidade significativa para nosso tamanho de dataset\n\ndf[['cabin_deck', 'cabin_num', 'cabin_side']] = df['Cabin'].str.split('/', expand=True)\ndf = df.drop(columns=['Cabin'])\n\ndf['Destination'] = df['Destination'].fillna('TRAPPIST-1e') # TRAPPIST-1e representa 69% dos dados, podemos utiliz\u00e1-lo para preencher os nulos\n\nmediana_age = df['Age'].median()\ndf['Age'] = df['Age'].fillna(mediana_age) # Preenchemos com a mediana para sermos resistentes \u00e0 outliers\n\ndf['VIP'] = df['VIP'].fillna(False) # Os n\u00e3o VIPS representam 97% do dataset.\n\n# Os valores utilizados no preenchimento representam cerca de 60% ou mais das linhas, \u00e9 melhor do que pegarmos a m\u00e9dia.\ndf['RoomService'] = df['RoomService'].fillna(0)\ndf['FoodCourt'] = df['FoodCourt'].fillna(0)\ndf['ShoppingMall'] = df['ShoppingMall'].fillna(0)\ndf['Spa'] = df['Spa'].fillna(0)\ndf['VRDeck'] = df['VRDeck'].fillna(0)\n\n# Como a coluna Name n\u00e3o ser\u00e1 utilizada pelo nosso modelo por n\u00e3o conter nenhuma informa\u00e7\u00e3o relevante podemos manter os registros, e apenas apagar a coluna futuramente.\n\n# Transformando dados categ\u00f3ricos em valores 0 e 1:\ndf = pd.get_dummies(df, columns=['HomePlanet', 'Destination', 'cabin_deck', 'cabin_side'])\ncolunas_booleanas = df.select_dtypes(include=['bool', 'boolean']).columns\nfor coluna in colunas_booleanas:\n    df[coluna] = df[coluna].astype('Int64')\ndf = df.drop(columns=['PassengerId', 'Name'])\n\n# Utilizando MinMaxScaler para manter os dados em uma escala de -1 a 1:\nscaler = MinMaxScaler(feature_range=(-1, 1))\ncolunas_numericas = df.select_dtypes(include=np.number).columns\ndf_normalizado = df.copy()\ndf_normalizado[colunas_numericas] = scaler.fit_transform(df_normalizado[colunas_numericas])\n\n\ncolunas_para_visualizar = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n\nfig, axes = plt.subplots(nrows=len(colunas_para_visualizar), ncols=2, figsize=(12, 10))\n\nfig.suptitle('Histogramas Antes e Depois da Normaliza\u00e7\u00e3o', fontsize=16)\n\nfor i, col in enumerate(colunas_para_visualizar):\n    # Plotar o histograma dos dados originais (\"Antes\")\n    axes[i, 0].hist(df[col], bins=20, color='skyblue', edgecolor='black')\n    axes[i, 0].set_title(f'{col} (Antes da Normaliza\u00e7\u00e3o)')\n    axes[i, 0].set_xlabel('Valor Original')\n    axes[i, 0].set_ylabel('Frequ\u00eancia')\n\n    # Plotar o histograma dos dados normalizados (\"Depois\")\n    axes[i, 1].hist(df_normalizado[col], bins=20, color='salmon', edgecolor='black')\n    axes[i, 1].set_title(f'{col} (Depois da Normaliza\u00e7\u00e3o)')\n    axes[i, 1].set_xlabel('Valor Normalizado [-1, 1]')\n    axes[i, 1].set_ylabel('Frequ\u00eancia')\n\nplt.tight_layout(rect=[0, 0, 1, 0.96])\n\nplt.show()\n</code></pre>"},{"location":"data/main/#pre-processamento-dos-dados-e-justificativa-das-escolhas","title":"Pr\u00e9-processamento dos Dados e Justificativa das Escolhas","text":"<p>Para preparar os dados para uma rede neural, aplicamos as seguintes etapas de pr\u00e9-processamento:</p> <ol> <li> <p>Tratamento de Valores Ausentes:</p> <ul> <li><code>HomePlanet</code>: Imputamos os valores ausentes com o valor 'Earth', pois \u00e9 o valor predominante.</li> <li><code>CryoSleep</code>: Imputamos os valores ausentes com o valor False, pois \u00e9 o valor predominante.</li> <li><code>Embarked</code>: Imputamos os valores ausentes com a moda (valor mais frequente), pois \u00e9 uma feature categ\u00f3rica.</li> <li><code>Cabin</code>: Removemos os registros em que essa coluna tinha valores nulos, pois seria dif\u00edcil utilizar algum tipo de m\u00e9trica que n\u00e3o atrapalhasse nosso modelo. Al\u00e9m disso separamos essa coluna em 3: 'cabin_deck', 'cabin_num', 'cabin_side'.</li> <li><code>Destination</code>: Imputamos os valores ausentes com o valor 'TRAPPIST-1e', pois \u00e9 o valor predominante. </li> <li><code>Age</code>: Imputamos os valores ausentes com a mediana para sermos resistentes \u00e0 outliers. </li> <li><code>VIP</code>: Imputamos os valores ausentes com o valor False, pois representam 97% do dataset.</li> <li><code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code>: Imputamos os valores ausentes com o valor 0, pois \u00e9 o valor predominante.</li> </ul> </li> <li> <p>Codifica\u00e7\u00e3o de Features Categ\u00f3ricas:</p> <ul> <li>Aplicamos One-Hot Encoding para converter essas features categ\u00f3ricas em representa\u00e7\u00f5es num\u00e9ricas bin\u00e1rias. Isso \u00e9 crucial para redes neurais, que operam com dados num\u00e9ricos.</li> </ul> </li> <li> <p>Escalonamento de Features Num\u00e9ricas:</p> <ul> <li>Aplicamos <code>MinMaxScaler</code> para normalizar essas features para um intervalo entre -1 e 1. O escalonamento \u00e9 importante para redes neurais porque diferentes escalas de features podem levar a gradientes desbalanceados durante o treinamento, dificultando a converg\u00eancia do modelo. <code>MinMaxScaler</code> \u00e9 escolhido para manter a rela\u00e7\u00e3o original entre os valores, o que \u00e9 adequado para dados com distribui\u00e7\u00f5es variadas.</li> </ul> </li> <li> <p>Visualize os resultados:</p> <ul> <li>Crie histogramas para um ou dois recursos num\u00e9ricos (como FoodCourtou Age) antes e depois do dimensionamento para mostrar o efeito da sua transforma\u00e7\u00e3o.</li> </ul> </li> </ol> <p></p>"},{"location":"projeto/main/","title":"Main","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"},{"location":"roteiro1/main/","title":"Main","text":""},{"location":"roteiro1/main/#objetivo","title":"Objetivo","text":"<p>Aqui vai o objetivo macro do roteiro. Por que estamos fazendo o que estamos fazendo?</p>"},{"location":"roteiro1/main/#montagem-do-roteiro","title":"Montagem do Roteiro","text":"<p>Os pontos \"tarefas\" s\u00e3o os passos que devem ser seguidos para a realiza\u00e7\u00e3o do roteiro. Eles devem ser claros e objetivos. Com evid\u00eancias claras de que foram realizados.</p>"},{"location":"roteiro1/main/#tarefa-1","title":"Tarefa 1","text":"<p>Instalando o MAAS:</p> sudo snap install maas --channel=3.5/Stable <p></p> <p>Dashboard do MAAS</p> <p>Conforme ilustrado acima, a tela inicial do MAAS apresenta um dashboard com informa\u00e7\u00f5es sobre o estado atual dos servidores gerenciados. O dashboard \u00e9 composto por diversos pain\u00e9is, cada um exibindo informa\u00e7\u00f5es sobre um aspecto espec\u00edfico do ambiente gerenciado. Os pain\u00e9is podem ser configurados e personalizados de acordo com as necessidades do usu\u00e1rio.</p>"},{"location":"roteiro1/main/#tarefa-2","title":"Tarefa 2","text":""},{"location":"roteiro1/main/#app","title":"App","text":""},{"location":"roteiro1/main/#tarefa-1_1","title":"Tarefa 1","text":""},{"location":"roteiro1/main/#tarefa-2_1","title":"Tarefa 2","text":"<p>Exemplo de diagrama</p> <pre><code>architecture-beta\n    group api(cloud)[API]\n\n    service db(database)[Database] in api\n    service disk1(disk)[Storage] in api\n    service disk2(disk)[Storage] in api\n    service server(server)[Server] in api\n\n    db:L -- R:server\n    disk1:T -- B:server\n    disk2:T -- B:db</code></pre> <p>Mermaid</p>"},{"location":"roteiro1/main/#questionario-projeto-ou-plano","title":"Question\u00e1rio, Projeto ou Plano","text":"<p>Esse se\u00e7\u00e3o deve ser preenchida apenas se houver demanda do roteiro.</p>"},{"location":"roteiro1/main/#discussoes","title":"Discuss\u00f5es","text":"<p>Quais as dificuldades encontradas? O que foi mais f\u00e1cil? O que foi mais dif\u00edcil?</p>"},{"location":"roteiro1/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O que foi poss\u00edvel concluir com a realiza\u00e7\u00e3o do roteiro?</p>"},{"location":"roteiro2/main/","title":"Main","text":""},{"location":"roteiro2/main/#diagrama-de-classes-do-banco","title":"Diagrama de Classes do Banco","text":"<pre><code>classDiagram\n    class Conta {\n        - String id\n        # double saldo\n        - Cliente cliente\n        + sacar(double valor)\n        + depositar(double valor)\n    }\n    class Cliente {\n        - String id\n        - String nome\n        - List&lt;Conta&gt; contas\n    }\n    class PessoaFisica {\n        - String cpf\n    }\n    class PessoaJuridica {\n        - String cnpj\n    }\n    class ContaCorrente {\n        - double limite\n        + sacar(double valor)\n    }\n    class ContaPoupanca {\n        + sacar(double valor)\n    }\n    Conta *-- Cliente\n    Conta &lt;|-- ContaCorrente\n    Conta &lt;|-- ContaPoupanca\n    Cliente &lt;|-- PessoaFisica\n    Cliente &lt;|-- PessoaJuridica</code></pre>"},{"location":"roteiro2/main/#diagrama-de-sequencia-de-autorizacao","title":"Diagrama de Seq\u00fc\u00eancia de Autoriza\u00e7\u00e3o","text":"<pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Auth Service: request with token\n  Auth Service-&gt;&gt;Auth Service: decodes the token and extracts claims\n  Auth Service-&gt;&gt;Auth Service: verifies permissions\n  critical allowed\n    Auth Service-&gt;&gt;Secured Resource: authorizes the request\n    Secured Resource-&gt;&gt;User: returns the response\n  option denied\n    Auth Service--&gt;&gt;User: unauthorized message\n  end  </code></pre>"},{"location":"roteiro3/main/","title":"Main","text":"<p>Running the code below in Browser (Woooooowwwwww!!!!!!). <sup>1</sup></p> <p> Editor (session: default) Run <pre>import ssl\nimport pandas as pd\n\ndf = pd.DataFrame()\ndf['AAPL'] = pd.Series([1, 2, 3])\ndf['MSFT'] = pd.Series([4, 5, 6])\ndf['GOOGL'] = pd.Series([7, 8, 9])\n\nprint(df)\n</pre> Output Clear <pre></pre> </p> <ol> <li> <p>Pyodide \u21a9</p> </li> </ol>"},{"location":"roteiro4/main/","title":"Main","text":"<p>Se chegou aqui, \u00e9 porque voc\u00ea est\u00e1 interessado em saber mais. Logo, de brinde, como rodar um c\u00f3digo <code>Python</code> aqui.</p> 2025-09-02T12:52:20.930050 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <pre><code>Traceback (most recent call last):\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\curl_cffi\\requests\\session.py\", line 640, in request\n    c.perform()\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\curl_cffi\\curl.py\", line 365, in perform\n    self._check_error(ret, \"perform\")\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\curl_cffi\\curl.py\", line 187, in _check_error\n    raise error\ncurl_cffi.curl.CurlError: Failed to perform, curl: (77) error setting certificate verify locations:  CAfile: C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\certifi\\cacert.pem CApath: none. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\markdown_exec\\_internal\\formatters\\python.py\", line 71, in _run_python\n    exec_python(code, code_block_id, exec_globals)\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\markdown_exec\\_internal\\formatters\\_exec_python.py\", line 8, in exec_python\n    exec(compiled, exec_globals)  # noqa: S102\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"&lt;code block: n2&gt;\", line 15, in &lt;module&gt;\n    data = info.history(period='2y')\n            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\utils.py\", line 92, in wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\base.py\", line 101, in history\n    return self._lazy_load_price_history().history(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\base.py\", line 107, in _lazy_load_price_history\n    self._price_history = PriceHistory(self._data, self.ticker, self._get_ticker_tz(timeout=10))\n                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\base.py\", line 132, in _get_ticker_tz\n    if k in self.info:\n            ^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\ticker.py\", line 163, in info\n    return self.get_info()\n           ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\base.py\", line 298, in get_info\n    data = self._quote.info\n           ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\scrapers\\quote.py\", line 511, in info\n    self._fetch_info()\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\scrapers\\quote.py\", line 610, in _fetch_info\n    result = self._fetch(modules=modules)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\scrapers\\quote.py\", line 590, in _fetch\n    result = self._data.get_raw_json(_QUOTE_SUMMARY_URL_ + f\"/{self._symbol}\", params=params_dict)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\data.py\", line 432, in get_raw_json\n    response = self.get(url, params=params, timeout=timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\utils.py\", line 92, in wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\data.py\", line 370, in get\n    return self._make_request(url, request_method = self._session.get, params=params, timeout=timeout)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\utils.py\", line 92, in wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\data.py\", line 391, in _make_request\n    crumb, strategy = self._get_cookie_and_crumb()\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\utils.py\", line 92, in wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\data.py\", line 360, in _get_cookie_and_crumb\n    crumb = self._get_cookie_and_crumb_basic(timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\utils.py\", line 92, in wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\data.py\", line 239, in _get_cookie_and_crumb_basic\n    if not self._get_cookie_basic(timeout):\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\utils.py\", line 92, in wrapper\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\yfinance\\data.py\", line 196, in _get_cookie_basic\n    self._session.get(\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\curl_cffi\\requests\\session.py\", line 661, in get\n    return self.request(method=\"GET\", url=url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\curl_cffi\\requests\\session.py\", line 647, in request\n    raise error(str(e), e.code, rsp) from e\ncurl_cffi.requests.exceptions.SSLError: Failed to perform, curl: (77) error setting certificate verify locations:  CAfile: C:\\Users\\erikb\\OneDrive\\\u00c1rea de Trabalho\\redes_neurais\\env\\Lib\\site-packages\\certifi\\cacert.pem CApath: none. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.\n</code></pre> <p>Markdown-exec \u00e9 uma extens\u00e3o do Markdown que permite executar c\u00f3digo Python diretamente no Markdown. Isso \u00e9 \u00fatil para gerar resultados din\u00e2micos ou executar scripts de forma interativa.</p>"},{"location":"thisdocumentation/main/","title":"Main","text":""},{"location":"thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}